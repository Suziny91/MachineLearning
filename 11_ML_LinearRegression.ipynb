{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 함수\n",
    "\n",
    "$$\n",
    "Y = Wx + b\n",
    "$$\n",
    "\n",
    "x는 특성, y는 예측 값이다. \n",
    "W는 기울기, b는 y절편을 뜻하지만 W는 가중치(weight), b는 offset으로 부를 수도 있다.\n",
    "선형 회귀에서는 여러 샘플의 특성 값과 예측 값을 활용해 가장 적절한 w와 b를 구하는 것이 목적이다.\n",
    "### 평균 제곱 오차 (Mean Square Error)\n",
    "선형 회귀에서는 Coast 함수(또는 비용 함수)로 평균 제곱 오차를 사용한다. \n",
    "여기서 Coast 함수란 샘플 데이터와 타깃과의 유사도를 의미하며 Coast 함수가 최소가 되도록 \n",
    "파라미터를 학습시킨다. \n",
    "$$\n",
    "   \\frac{1}{n}\\sum(pred_i - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1., 2., 3., 4., 5., 6.])\n",
    "Y = np.array([9., 16., 23., 30., 37., 44.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W, B값은 0으로 초기화 되어져 있습니다.\n",
    "W = 0.0\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = len(X)\n",
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000 # 전체 데이터 셋에 대해 한 번 학습을 하는 사이클을 의미한다.\n",
    "learning_rate = 0.01 #학습속도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "    아랫 부분은 머신러닝 알고리즘을 활용하여 \n",
    "    전체 EPOCH 을 돌면서 가장 Cost가 낮은 W,B값을 찾아서 예측값을 출력해보세요\n",
    "    이때 위에 있는 MSE 함수 원리는 그대로 적용한 코드를 만들어서 손실 부분을 \n",
    "    계산하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (         0 /       5000) cost:778.655200, W:  2.217850, b:  0.519504\n",
      "Epoch (       100 /       5000) cost:  0.802846, W:  4.917105, b:  1.527024\n",
      "Epoch (       200 /       5000) cost:  0.793006, W:  4.261261, b:  1.760291\n",
      "Epoch (       300 /       5000) cost:  0.785669, W:  3.713047, b:  2.018396\n",
      "Epoch (       400 /       5000) cost:  0.780477, W:  3.258601, b:  2.298139\n",
      "Epoch (       500 /       5000) cost:  0.776925, W:  2.882856, b:  2.596044\n",
      "Epoch (       600 /       5000) cost:  0.774535, W:  2.571559, b:  2.908821\n",
      "Epoch (       700 /       5000) cost:  0.772935, W:  2.312318, b:  3.233612\n",
      "Epoch (       800 /       5000) cost:  0.771857, W:  2.094890, b:  3.568052\n",
      "Epoch (       900 /       5000) cost:  0.771124, W:  1.911056, b:  3.910244\n",
      "Epoch (      1000 /       5000) cost:  0.770619, W:  1.754317, b:  4.258689\n",
      "Epoch (      1100 /       5000) cost:  0.770265, W:  1.619568, b:  4.612208\n",
      "Epoch (      1200 /       5000) cost:  0.770014, W:  1.502797, b:  4.969876\n",
      "Epoch (      1300 /       5000) cost:  0.769832, W:  1.400840, b:  5.330963\n",
      "Epoch (      1400 /       5000) cost:  0.769699, W:  1.311191, b:  5.694890\n",
      "Epoch (      1500 /       5000) cost:  0.769600, W:  1.231847, b:  6.061195\n",
      "Epoch (      1600 /       5000) cost:  0.769525, W:  1.161199, b:  6.429507\n",
      "Epoch (      1700 /       5000) cost:  0.769468, W:  1.097943, b:  6.799525\n",
      "Epoch (      1800 /       5000) cost:  0.769424, W:  1.041012, b:  7.171003\n",
      "Epoch (      1900 /       5000) cost:  0.769389, W:  0.989532, b:  7.543738\n",
      "Epoch (      2000 /       5000) cost:  0.769362, W:  0.942775, b:  7.917563\n",
      "Epoch (      2100 /       5000) cost:  0.769340, W:  0.900135, b:  8.292339\n",
      "Epoch (      2200 /       5000) cost:  0.769323, W:  0.861104, b:  8.667947\n",
      "Epoch (      2300 /       5000) cost:  0.769309, W:  0.825251, b:  9.044289\n",
      "Epoch (      2400 /       5000) cost:  0.769297, W:  0.792210, b:  9.421279\n",
      "Epoch (      2500 /       5000) cost:  0.769288, W:  0.761669, b:  9.798847\n",
      "Epoch (      2600 /       5000) cost:  0.769280, W:  0.733358, b: 10.176929\n",
      "Epoch (      2700 /       5000) cost:  0.769273, W:  0.707047, b: 10.555472\n",
      "Epoch (      2800 /       5000) cost:  0.769268, W:  0.682532, b: 10.934430\n",
      "Epoch (      2900 /       5000) cost:  0.769263, W:  0.659639, b: 11.313763\n",
      "Epoch (      3000 /       5000) cost:  0.769259, W:  0.638213, b: 11.693434\n",
      "Epoch (      3100 /       5000) cost:  0.769256, W:  0.618120, b: 12.073412\n",
      "Epoch (      3200 /       5000) cost:  0.769253, W:  0.599241, b: 12.453671\n",
      "Epoch (      3300 /       5000) cost:  0.769250, W:  0.581469, b: 12.834185\n",
      "Epoch (      3400 /       5000) cost:  0.769248, W:  0.564711, b: 13.214933\n",
      "Epoch (      3500 /       5000) cost:  0.769246, W:  0.548883, b: 13.595896\n",
      "Epoch (      3600 /       5000) cost:  0.769245, W:  0.533911, b: 13.977056\n",
      "Epoch (      3700 /       5000) cost:  2.178940, W:  0.494619, b: 14.352604\n",
      "Epoch (      3800 /       5000) cost:577453.190353, W:-17.896384, b: 10.493142\n",
      "Epoch (      3900 /       5000) cost:719031.583498, W:-20.446651, b: 10.289234\n",
      "Epoch (      4000 /       5000) cost:864125.394898, W:-22.870986, b: 10.114388\n",
      "Epoch (      4100 /       5000) cost:1012794.775039, W:-25.200775, b:  9.961360\n",
      "Epoch (      4200 /       5000) cost:1165070.923572, W:-27.456561, b:  9.825409\n",
      "Epoch (      4300 /       5000) cost:1320971.640770, W:-29.652640, b:  9.703237\n",
      "Epoch (      4400 /       5000) cost:328203.490487, W:-14.098862, b: 13.677186\n",
      "Epoch (      4500 /       5000) cost:1413787.909546, W:-31.257331, b: 10.102154\n",
      "Epoch (      4600 /       5000) cost:3178079.609214, W:-48.725805, b:  6.455584\n",
      "Epoch (      4700 /       5000) cost:1302161.901439, W:-11.976747, b: 15.320751\n",
      "Epoch (      4800 /       5000) cost:2133333.332693, W: 14.080401, b: 21.718554\n",
      "Epoch (      4900 /       5000) cost:5980946.545302, W:-69.588999, b:  2.794846\n",
      "W: -54.649791\n",
      "b:   6.623125\n",
      "result : \n",
      "[ -48.0266657  -102.67645658 -157.32624747 -211.97603835 -266.62582923\n",
      " -321.27562011]\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # 1. 예측을 먼저 한다.\n",
    "    y_predict= X * W * b\n",
    "    \n",
    "    # 2. 예측한 후에 얼마나 잘 예측했는지의 결과...Cost를 알 수 있다.\n",
    "    cost = np.sum((y_predict - Y) ** 2) / n_data # MSE 함수를 코드로 정의\n",
    "    \n",
    "    # 3. 경사하강법 원리에 의해사 W,b 값을 조금씩 보정해 나간다.\n",
    "    W -= learning_rate * ((y_predict - Y) * X).mean()\n",
    "    b -= learning_rate * (y_predict - Y).mean()\n",
    "    \n",
    "    \n",
    "    if i % 100 ==0:\n",
    "        print('Epoch ({:10d} / {:10d}) cost:{:10f}, W:{:10f}, b:{:10f}'.format(i, epochs, cost,W,b))\n",
    "  \n",
    "    \n",
    "print('W: {:10f}'.format(W))\n",
    "print('b: {:10f}'.format(b))\n",
    "print('result : ')\n",
    "print(X * W + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
